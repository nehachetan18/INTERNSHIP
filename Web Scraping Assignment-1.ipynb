{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a233bd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\achintya\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "                          Headers\n",
      "0                       Main Page\n",
      "1            Welcome to Wikipedia\n",
      "2   From today's featured article\n",
      "3                Did you know ...\n",
      "4                     In the news\n",
      "5                     On this day\n",
      "6      From today's featured list\n",
      "7        Today's featured picture\n",
      "8        Other areas of Wikipedia\n",
      "9     Wikipedia's sister projects\n",
      "10            Wikipedia languages\n"
     ]
    }
   ],
   "source": [
    "# 1) Write a python program to display all the header tags from wikipedia.org and make data frame\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "response=requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "header_tags=soup.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "headers=[tag.text.strip()for tag in header_tags]\n",
    "df=pd.DataFrame({\"Headers\":headers})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e1aa3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd7d8a4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\achintya\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\achintya\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Empty DataFrame\n",
      "Columns: [Name, Term of Office]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 2)Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "# from https://presidentofindia.nic.in/former-presidents.htm and make data frame.\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "response=requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "\n",
    "soup=BeautifulSoup(response.content,'html.parser')\n",
    "president_list=[]\n",
    "\n",
    "for row in soup.find_all(\"tr\")[1:]:\n",
    "    cols=row.find_all(\"td\")\n",
    "    name=cols[0].text.strip()\n",
    "    term_of_office=cols[1].text.strip()\n",
    "    president_list.append((name,term_of_office))\n",
    "df=pd.DataFrame(president_list,columns=[\"Name\",\"Term of Office\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f52d1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams:\n",
      "  Position              Team Matches Points Rating\n",
      "0        1    Australia\\nAUS      25  3,014    121\n",
      "1        2     Pakistan\\nPAK      25  2,997    120\n",
      "2        3        India\\nIND      37  4,204    114\n",
      "3        4   New Zealand\\nNZ      28  2,957    106\n",
      "4        5      England\\nENG      25  2,480     99\n",
      "5        6  South Africa\\nSA      21  2,047     97\n",
      "6        7   Bangladesh\\nBAN      32  2,941     92\n",
      "7        8     Sri Lanka\\nSL      35  3,215     92\n",
      "8        9  Afghanistan\\nAFG      21  1,687     80\n",
      "9       10   West Indies\\nWI      38  2,582     68\n",
      "\n",
      "Top 10 ODI Batsmen:\n",
      "Empty DataFrame\n",
      "Columns: [Position, Player, Team, Rating]\n",
      "Index: []\n",
      "\n",
      "Top 10 ODI Bowlers:\n",
      "Empty DataFrame\n",
      "Columns: [Position, Player, Team, Rating]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "#a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "#b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "#c) Top 10 ODI bowlers along with the records of their team andrating.\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to scrape and parse data from a URL\n",
    "def scrape_and_parse(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "# Function to get top teams, batsmen, or bowlers data\n",
    "def get_top_data(url, columns):\n",
    "    soup = scrape_and_parse(url)\n",
    "    rows = soup.select('table.table tbody tr')\n",
    "\n",
    "    data = []\n",
    "    for row in rows:\n",
    "        cols = row.find_all(['th', 'td'])\n",
    "        cols = [col.text.strip() for col in cols]\n",
    "        data.append(cols)\n",
    "\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    return df\n",
    "\n",
    "# a) Top 10 ODI teams in men’s cricket along with the records for matches, points, and rating.\n",
    "teams_url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "teams_columns = ['Position', 'Team', 'Matches', 'Points', 'Rating']\n",
    "top_teams_df = get_top_data(teams_url, teams_columns)[:10]\n",
    "\n",
    "# b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "batsmen_url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting'\n",
    "batsmen_columns = ['Position', 'Player', 'Team', 'Rating']\n",
    "top_batsmen_df = get_top_data(batsmen_url, batsmen_columns)[:10]\n",
    "\n",
    "# c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "bowlers_url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling'\n",
    "bowlers_columns = ['Position', 'Player', 'Team', 'Rating']\n",
    "top_bowlers_df = get_top_data(bowlers_url, bowlers_columns)[:10]\n",
    "\n",
    "# Print the data frames\n",
    "print(\"Top 10 ODI teams:\")\n",
    "print(top_teams_df)\n",
    "\n",
    "print(\"\\nTop 10 ODI Batsmen:\")\n",
    "print(top_batsmen_df)\n",
    "\n",
    "print(\"\\nTop 10 ODI Bowlers:\")\n",
    "print(top_bowlers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c25e814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams in women’s cricket:\n",
      "   Pos           Team T  Matches M  Points P  Rating R\n",
      "0    1    Australia AUS         26      4290       165\n",
      "1    2      England ENG         31      3875       125\n",
      "2    3  South Africa SA         26      3098       119\n",
      "3    4        India IND         30      3039       101\n",
      "4    5   New Zealand NZ         28      2688        96\n",
      "5    6   West Indies WI         29      2743        95\n",
      "6    7   Bangladesh BAN         17      1284        76\n",
      "7    8     Sri Lanka SL         12       820        68\n",
      "8    9     Thailand THA         13       883        68\n",
      "9   10     Pakistan PAK         27      1678        62\n",
      "\n",
      "Top 10 women’s ODI Batting players:\n",
      "                                                 Pos                Player  \\\n",
      "0                                             1  (0)  Natalie Sciver-Brunt   \n",
      "1                                             2  (0)   Chamari Athapaththu   \n",
      "2                                             3  (0)           Beth Mooney   \n",
      "3                                             4  (0)       Laura Wolvaardt   \n",
      "4  5  (1) This player has moved up in the ranking...       Smriti Mandhana   \n",
      "5  6  (1) This player has moved down in the ranki...          Alyssa Healy   \n",
      "6                                             7  (0)      Harmanpreet Kaur   \n",
      "7                                             8  (0)          Ellyse Perry   \n",
      "8                                             9  (0)           Meg Lanning   \n",
      "9                                            10  (0)       Stafanie Taylor   \n",
      "\n",
      "  Team  Rating             Career Best Rating  \n",
      "0  ENG     803    803 v Australia, 18/07/2023  \n",
      "1   SL     758  758 v New Zealand, 03/07/2023  \n",
      "2  AUS     751      776 v England, 12/07/2023  \n",
      "3   SA     732    741 v Australia, 22/03/2022  \n",
      "4  IND     708      797 v England, 28/02/2019  \n",
      "5  AUS     702      785 v England, 03/04/2022  \n",
      "6  IND     694      731 v England, 21/09/2022  \n",
      "7  AUS     686  766 v West Indies, 11/09/2019  \n",
      "8  AUS     682  834 v New Zealand, 24/02/2016  \n",
      "9   WI     618     766 v Pakistan, 07/07/2021  \n",
      "\n",
      "Top 10 women’s ODI all-rounder:\n",
      "       Pos                Player Team  Rating              Career Best Rating\n",
      "0   1  (0)  Natalie Sciver-Brunt  ENG     421     421 v Australia, 18/07/2023\n",
      "1   2  (0)      Ashleigh Gardner  AUS     389       389 v Ireland, 28/07/2023\n",
      "2   3  (0)       Hayley Matthews   WI     382       392 v Ireland, 26/06/2023\n",
      "3   4  (0)        Marizanne Kapp   SA     349   419 v West Indies, 10/09/2021\n",
      "4   5  (0)          Ellyse Perry  AUS     329   548 v West Indies, 11/09/2019\n",
      "5   6  (0)           Amelia Kerr   NZ     328   356 v West Indies, 25/09/2022\n",
      "6   7  (0)         Deepti Sharma  IND     312  397 v South Africa, 09/10/2019\n",
      "7   8  (0)         Jess Jonassen  AUS     241   308 v West Indies, 11/09/2019\n",
      "8   9  (0)         Sophie Devine   NZ     233     305 v Australia, 05/10/2020\n",
      "9  10  (0)              Nida Dar  PAK     232     232 v Australia, 21/01/2023\n"
     ]
    }
   ],
   "source": [
    "#4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "#b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n",
    "#c) Top 10 women’s ODI all-rounder along with the records of their team and rating\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to scrape and create dataframes\n",
    "def scrape_and_create_dataframe(url, table_index):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    table = soup.find_all('table')[table_index]\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    return df\n",
    "\n",
    "# a) Top 10 ODI teams in women’s cricket\n",
    "url_teams = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "df_teams = scrape_and_create_dataframe(url_teams, 0)\n",
    "\n",
    "# b) Top 10 women’s ODI Batting players\n",
    "url_batting = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting'\n",
    "df_batting = scrape_and_create_dataframe(url_batting, 0)\n",
    "\n",
    "# c) Top 10 women’s ODI all-rounder\n",
    "url_allrounder = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder'\n",
    "df_allrounder = scrape_and_create_dataframe(url_allrounder, 0)\n",
    "\n",
    "# Display the dataframes\n",
    "print(\"Top 10 ODI teams in women’s cricket:\")\n",
    "print(df_teams.head(10))\n",
    "\n",
    "print(\"\\nTop 10 women’s ODI Batting players:\")\n",
    "print(df_batting.head(10))\n",
    "\n",
    "print(\"\\nTop 10 women’s ODI all-rounder:\")\n",
    "print(df_allrounder.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e666fcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Headline, Time, News Link]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#5) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and make data frame\n",
    "#i) Headline\n",
    "#ii) Time\n",
    "#iii) News Link\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL to scrape\n",
    "url = \"https://www.cnbc.com/world/?region=world\"\n",
    "\n",
    "# Send a request to the URL and get the HTML content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the news articles\n",
    "articles = soup.find_all(\"div\", class_=\"Card-title\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "headlines = []\n",
    "times = []\n",
    "links = []\n",
    "\n",
    "# Extract data from the articles\n",
    "for article in articles:\n",
    "    headline = article.text.strip()\n",
    "    time = article.find_next(\"time\").text.strip()\n",
    "    link = \"https://www.cnbc.com\" + article.parent['href']\n",
    "    \n",
    "    headlines.append(headline)\n",
    "    times.append(time)\n",
    "    links.append(link)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Headline': headlines,\n",
    "    'Time': times,\n",
    "    'News Link': links\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1836f77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Paper Title, Authors, Published Date, Paper URL]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#6) Write a python program to scrape the details of most downloaded articles from AI in last 90days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "#Scrape below mentioned details and make data frame\n",
    "#i) Paper Title\n",
    "#ii) Authors\n",
    "#iii) Published Date\n",
    "#iv) Paper URL\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\"\n",
    "\n",
    "# Send a request to the URL and get the HTML content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "paper_titles = []\n",
    "authors = []\n",
    "published_dates = []\n",
    "paper_urls = []\n",
    "\n",
    "# Find the articles in the HTML\n",
    "articles = soup.find_all(\"div\", class_=\"most-downloaded-article\")\n",
    "\n",
    "# Loop through the articles and extract information\n",
    "for article in articles:\n",
    "    paper_title = article.find(\"a\", class_=\"download-article-title\").text\n",
    "    author = article.find(\"div\", class_=\"text-xs\").text.strip()\n",
    "    published_date = article.find(\"div\", class_=\"published-online\").text.strip()\n",
    "    paper_url = article.find(\"a\", class_=\"download-article-title\")[\"href\"]\n",
    "\n",
    "    paper_titles.append(paper_title)\n",
    "    authors.append(author)\n",
    "    published_dates.append(published_date)\n",
    "    paper_urls.append(paper_url)\n",
    "\n",
    "# Create a data frame\n",
    "data = {\n",
    "    \"Paper Title\": paper_titles,\n",
    "    \"Authors\": authors,\n",
    "    \"Published Date\": published_dates,\n",
    "    \"Paper URL\": paper_urls\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the data frame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "148fa278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Restaurant Name, Cuisine, Location, Ratings, Image URL]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#7) Write a python program to scrape mentioned details from dineout.co.inand make data frame\n",
    "#i) Restaurant name\n",
    "#ii) Cuisine\n",
    "#iii) Location\n",
    "#iv) Ratings\n",
    "#v) Image URL\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the URL to scrape\n",
    "url = \"https://www.dineout.co.in/delhi-restaurants\"\n",
    "\n",
    "# Make a request to the website\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Initialize lists to store data\n",
    "restaurant_names = []\n",
    "cuisines = []\n",
    "locations = []\n",
    "ratings = []\n",
    "image_urls = []\n",
    "\n",
    "# Find all the restaurant cards\n",
    "restaurant_cards = soup.find_all('div', class_='restnt-card-main')\n",
    "\n",
    "# Iterate through each restaurant card\n",
    "for card in restaurant_cards:\n",
    "    # Get restaurant name\n",
    "    restaurant_name = card.find('div', class_='restnt-info').h2.text.strip()\n",
    "    restaurant_names.append(restaurant_name)\n",
    "\n",
    "    # Get cuisine\n",
    "    cuisine = card.find('span', class_='double-line-ellipsis').text.strip()\n",
    "    cuisines.append(cuisine)\n",
    "\n",
    "    # Get location\n",
    "    location = card.find('div', class_='restnt-loc').text.strip()\n",
    "    locations.append(location)\n",
    "\n",
    "    # Get rating\n",
    "    rating = card.find('span', class_='green').text.strip()\n",
    "    ratings.append(rating)\n",
    "\n",
    "    # Get image URL\n",
    "    image_url = card.find('img')['data-src']\n",
    "    image_urls.append(image_url)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Restaurant Name': restaurant_names,\n",
    "    'Cuisine': cuisines,\n",
    "    'Location': locations,\n",
    "    'Ratings': ratings,\n",
    "    'Image URL': image_urls\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259f619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
